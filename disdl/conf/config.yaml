# conf/config.yaml

available_datasets:
  # - name: "imagenet"
  #   storage_backend: "s3://imagenet1k-sdl/train/"
  #   batch_size: 128
  #   shuffle: true
  #   drop_last: false
  #   num_partitions: 1
  #   prefetch_lambda_name: "CreateImageNetTrainingBatch"

  - name: cifar10
    storage_backend: s3
    local_storage_path: data\cifar10\train
    s3_storage_path: s3://sdl-cifar10/train
    batch_size: 128
    shuffle: true
    drop_last: false
    num_partitions: 1
    prefetch_lambda_name: CreateVisionTrainingBatch

  # - name: "mscoco"
  #   storage_backend: "s3://datasets/coco/train2017"
  #   batch_size: 64
  #   shuffle: true
  #   drop_last: true
  #   num_partitions: 2
  #   prefetch_lambda_name: "CreateCOCOTrainingBatch"

cache_address: "redis://localhost:6379"
enable_prefetching: false
prefetch_cost_cap_per_hour: 0.25
# prefetch_simulation_time: null  # Optional if simulating fetch cost/time



hydra:
  run:
    dir: .  # Current directory or a specific directory where Ray Tune expects to find it
  sweep:
    dir: .  # Same as above
  output_subdir: null
  job_logging:
    level: DISABLE  # Disable job-specific logging
  hydra_logging:
    level: DISABLE  # Disable Hydra-specific logging
