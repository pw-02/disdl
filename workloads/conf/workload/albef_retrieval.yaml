# dataloading configuration
name: albef_retrieval
s3_train_prefix: s3://coco-dataset/coco_train.json
s3_val_prefix: s3://coco-dataset/data/coco_val.json
num_pytorch_workers: 0

alpha: 0.4
weight_decay: 0.02
learning_rate: 1e-5
precision: 16-mixed

run_training: True
run_validation: False
validation_frequency: 1000000 #every n epochs
checkpoint_frequency: .inf #every n epochs
max_epochs: null
max_steps: 2500
batch_size: 128 #Number of samples between optimizer steps across data-parallel ranks
limit_train_batches: null
limit_val_batches: .inf
gpu_time: null

# Anchor definitions
hidden_size: &hidden_size 512
vocab_size: &vocab_size 30522
type_vocab_size: &type_vocab_size 2
max_position_embeddings: &max_position_embeddings 256
pad_token_id: &pad_token_id 0
embed_size: &embed_size 256

vision_encoder_args:
  hidden_size: *hidden_size
  image_size: 384
  patch_size: 48
  num_hidden_layers: 4
  num_attention_heads: 4
  mlp_dim: 2048
  dropout: 0.1
  attention_dropout: 0.0
  layer_norm_eps: 1e-6

text_encoder_args:
  vocab_size: *vocab_size
  hidden_size: *hidden_size
  type_vocab_size: *type_vocab_size
  max_position_embeddings: *max_position_embeddings
  pad_token_id: *pad_token_id
  num_hidden_layers: 4
  num_attention_heads: 8
  intermediate_size: 2048
  layer_norm_eps: 1e-12
  dropout: 0.0

multimodal_encoder_args:
  hidden_size: *hidden_size
  num_hidden_layers: 4
  num_attention_heads: 8
  intermediate_size: 2048
  layer_norm_eps: 1e-12

projection_args:
  in_features: *hidden_size
  out_features: *embed_size

similarity_args:
  embed_size: *embed_size
  queue_size: 65536
  temp: 0.07
